{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b0f525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:30.419471Z",
     "start_time": "2025-06-15T23:18:30.405974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "def set_css_in_cell_output():\n",
    "    display(HTML('''\n",
    "        <style>\n",
    "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
    "            .widget-label {color: #d5d5d5 !important;}\n",
    "        </style>\n",
    "    '''))\n",
    "\n",
    "get_ipython().events.register('pre_run_cell', set_css_in_cell_output)\n",
    "from IPython.core import ultratb\n",
    "ultratb.VerboseTB._tb_highlight = \"bg:#0D0D0D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec3d23f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:31.840628Z",
     "start_time": "2025-06-15T23:18:30.688211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import tiktoken\n",
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "import traceback\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from jsonschema import validate\n",
    "from openai import OpenAI, RateLimitError, APITimeoutError, InternalServerError, Timeout\n",
    "from tenacity import retry, stop_after_attempt, wait_incrementing, retry_if_exception_type, after_log, before_sleep_log\n",
    "import logging\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e690b62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:32.088628Z",
     "start_time": "2025-06-15T23:18:31.844127Z"
    }
   },
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY = ''        # private openrouter api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c39d76b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:32.449668Z",
     "start_time": "2025-06-15T23:18:32.444888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "request_limit_per_minute = 500\n",
    "token_limit_per_minute = 2e6\n",
    "\n",
    "request_timeout_seconds = 120   # maximum wait time for openAI to respond before triggering request timeout \n",
    "request_max_retries = 1         # number to times to automatically retry failed requests\n",
    "tpm_wait_polling_seconds = 10    # if our internal TPM estimate thinks TPM limit is exceeded, how often to check if limit cleared\n",
    "\n",
    "# global logger for static classes\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbfee26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:33.095686Z",
     "start_time": "2025-06-15T23:18:33.071774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ChatGPT:\n",
    "    def __init__(self, model_provider_order,\n",
    "                 halt_on_error=True,\n",
    "                 is_verbose=True,\n",
    "                 timeout=request_timeout_seconds,\n",
    "                 max_retries=request_max_retries,\n",
    "                 request_limit_per_minute=request_limit_per_minute,\n",
    "                 token_limit_per_minute=token_limit_per_minute,\n",
    "                 tpm_wait_polling_seconds=tpm_wait_polling_seconds,\n",
    "                 logger=logger,\n",
    "                 api_key=OPENROUTER_API_KEY,\n",
    "                 limit_manager_db_password=LIMIT_MANAGER_DB_PASSWORD):\n",
    "        self.model, self.provider_order, self.model_canonical_name = model_provider_order\n",
    "        self.halt_on_error = halt_on_error\n",
    "        self.is_verbose = is_verbose\n",
    "        self.tpm_wait_polling_seconds = tpm_wait_polling_seconds\n",
    "        self.request_limit_per_minute = request_limit_per_minute\n",
    "        self.request_delay_seconds = 60.0 / request_limit_per_minute\n",
    "        self.token_limit_per_minute = token_limit_per_minute\n",
    "        self.response_history = []\n",
    "        self.message_history = {}\n",
    "        self.logger = logger\n",
    "        self.limit_manager_db_password = limit_manager_db_password\n",
    "        likert_options = [\n",
    "            \"Very Inaccurate\",\n",
    "            \"Moderately Inaccurate\",\n",
    "            \"Neither Accurate nor Inaccurate\",\n",
    "            \"Moderately Accurate\",\n",
    "            \"Very Accurate\",\n",
    "        ]\n",
    "        # Sort by length to match longer options (e.g., \"Strongly Agree\") before shorter ones (e.g., \"Agree\")\n",
    "        self.likert_options = sorted(likert_options, key=len, reverse=True)\n",
    "        self.default_seed = 1 if 'x-ai' in self.model else 0\n",
    "        \n",
    "        self.client = OpenAI(base_url=\"https://openrouter.ai/api/v1\",\n",
    "                             api_key = api_key,\n",
    "                             timeout=timeout,\n",
    "                             max_retries=max_retries)\n",
    "\n",
    "        \n",
    "    def extract_likert_response(self, content):\n",
    "        content_lower = content.lower()\n",
    "        for option in self.likert_options:\n",
    "            pattern = r'\\b' + re.escape(option.lower()) + r'\\b'\n",
    "            match = re.search(pattern, content_lower)\n",
    "            if match:\n",
    "                return json.dumps({\"response\": option})\n",
    "        raise Exception(\"No Likert match found in: \", content)    \n",
    "    \n",
    "    \n",
    "    def get_running_cost_num_prompt_completion_tokens(self):\n",
    "        \"\"\"\n",
    "        This function computes the total cost (estimated) of all\n",
    "        messages sent by the instance of ChatGPT called from\n",
    "        Returns: total_running_cost, total_num_prompt_tokens, total_num_response_tokens\n",
    "        \"\"\"\n",
    "        n_prompt_tokens = np.sum([x.usage.prompt_tokens for x in self.response_history])\n",
    "        n_completion_tokens = np.sum([x.usage.completion_tokens for x in self.response_history])\n",
    "        total_cost = sum(r.usage.cost for r in self.response_history)\n",
    "        return (total_cost,\n",
    "                n_prompt_tokens,\n",
    "                n_completion_tokens)\n",
    "\n",
    "    def get_key_usage_credits(self):\n",
    "        # get what OpenRouter says the api key has used in total\n",
    "        # returns usage, total credits available\n",
    "        resp = requests.get(\n",
    "            \"https://openrouter.ai/api/v1/credits\",\n",
    "            headers={\"Authorization\": f\"Bearer {self.client.api_key}\"}\n",
    "        )\n",
    "        resp.raise_for_status()\n",
    "        info = resp.json()[\"data\"]\n",
    "        return info[\"total_usage\"], info[\"total_credits\"]\n",
    "\n",
    "    # retry failing requests starting with 10 second wait,\n",
    "    # increasing wait time by 10 seconds each retry, up to a max window of 120s (or 5 times)\n",
    "    # the goal is to try to avoid hitting backoff,\n",
    "    # we treat this as a last resort because of its runtime cost\n",
    "    @retry(wait=wait_incrementing(start=10, increment=10, max=120),\n",
    "           stop=stop_after_attempt(5),\n",
    "           retry=retry_if_exception_type((RateLimitError, APITimeoutError, InternalServerError, Timeout)),\n",
    "           before_sleep=before_sleep_log(logger, logging.INFO),\n",
    "           after=after_log(logger, logging.INFO))\n",
    "    def completion_with_backoff(self, client, **kwargs):\n",
    "        return client.chat.completions.create(**kwargs)\n",
    "\n",
    "\n",
    "    def check_internal_TPM_tracker(self, n_message_tokens):\n",
    "        \"\"\"\n",
    "        Checks internal TPM count to see if a message with length = n_message_tokens\n",
    "        can be sent. If not, it waits (sleeps - blocking) until the message delivery\n",
    "        meets into TPM limit\n",
    "        \"\"\"\n",
    "        now = datetime.datetime.now()\n",
    "        one_minute_ago = now + datetime.timedelta(seconds=-60)\n",
    "        self.token_count_history = [x for x in self.token_count_history if x[1] > one_minute_ago]\n",
    "        n_tokens_past_minute = np.sum([x[0] for x in self.token_count_history]) + n_message_tokens\n",
    "        # fixed delay waiting if TPM exceeded over past minute\n",
    "        # this is cpu polling, so it doesnt cost money or much compute\n",
    "        while n_tokens_past_minute > self.token_limit_per_minute:\n",
    "            if self.is_verbose: self.logger.info(f'Internal TPM limit exceeded, waiting for {self.tpm_wait_polling_seconds} seconds...')\n",
    "            time.sleep(self.tpm_wait_polling_seconds)\n",
    "            now = datetime.datetime.now()\n",
    "            one_minute_ago = now + datetime.timedelta(seconds=-60)\n",
    "            self.token_count_history = [x for x in self.token_count_history if x[1] > one_minute_ago]\n",
    "            n_tokens_past_minute = np.sum([x[0] for x in self.token_count_history]) + n_message_tokens\n",
    "        now = datetime.datetime.now()\n",
    "        self.token_count_history.append((n_message_tokens, now))\n",
    "\n",
    "\n",
    "    def send_message(self, system_role, message, json_schema, validate_response=True):\n",
    "        \"\"\"\n",
    "        This is the primary function used to send messages to GPT and get responses\n",
    "        Steps are:\n",
    "          - check that json schema meets our basic requirements\n",
    "          - handle RPM and TPM limits as best as we can\n",
    "            (when openai rejects requests for exceeding limits its much slower)\n",
    "          - build and send the message using openai ChatCompletion api\n",
    "          - perform basic validation on GPT's response\n",
    "        This function either returns a ChatCompletion response object or None (if failure occurred)\n",
    "        Errors are propogated using raised Exceptions\n",
    "        \"\"\"\n",
    "        # sleep based on RPM limit (lazy logic, avoids keeping running count of actual requests per minute)\n",
    "        time.sleep(self.request_delay_seconds)\n",
    "\n",
    "        # check TPM limit (not lazy, uses running count of tokens per minute)\n",
    "        try:\n",
    "            encoding = tiktoken.encoding_for_model(self.model)\n",
    "        except:\n",
    "            encoding = tiktoken.encoding_for_model('gpt-4')\n",
    "        n_message_tokens = len(encoding.encode(system_role)) + len(encoding.encode(message))\n",
    "        self.logger.info(f'processing message with {n_message_tokens} tokens...')\n",
    "        if n_message_tokens > self.token_limit_per_minute:\n",
    "            return self.bad_response_output(f'Unable to send message as it exceeds TPM. Number of tokens in message = {n_message_tokens}')\n",
    "                \n",
    "        # build and send message over openai-api\n",
    "        message_id = len(self.message_history.keys())\n",
    "        self.message_history[message_id] = [] if 'x-ai' in self.model else [{\"role\": \"system\", \"content\": system_role}]\n",
    "        self.message_history[message_id].append({\"role\": \"user\", \"content\": message})\n",
    "        try:\n",
    "            response = self.completion_with_backoff(self.client,\n",
    "                                                    model=self.model,\n",
    "                                                    messages=self.message_history[message_id],\n",
    "                                                    temperature=0,\n",
    "                                                    stream=False,\n",
    "                                                    extra_body={\"usage\": {\"include\": True},\n",
    "                                                                \"reasoning\": {# One of the following (not both):\n",
    "                                                                              \"effort\": \"medium\", # Can be \"high\", \"medium\", or \"low\" (OpenAI-style)\n",
    "                                                                              # Optional: Default is false. All models support this.\n",
    "                                                                              \"exclude\": False # Set to true to exclude reasoning tokens from response\n",
    "                                                                              },\n",
    "                                                                \"provider\": {\"order\": self.provider_order, \n",
    "                                                                             \"sort\": \"price\",\n",
    "                                                                             \"data_collection\": \"deny\",\n",
    "                                                                             \"allow_fallbacks\": False}},\n",
    "                                                    response_format={\"type\": \"json_schema\",\n",
    "                                                                     \"json_schema\": json_schema},\n",
    "                                                    seed=self.default_seed, logprobs=False)\n",
    "            \n",
    "            self.response_history.append(response)\n",
    "            # reasoning models dont return a content field\n",
    "            if response.choices[0].message.content is None:\n",
    "                self.bad_response_output(f'None in message content')\n",
    "                return None\n",
    "            elif response.choices[0].message.content == '':\n",
    "                if hasattr(response.choices[0].message, 'reasoning'):\n",
    "                    if response.choices[0].message.reasoning != '':\n",
    "                        response.choices[0].message.content = response.choices[0].message.reasoning\n",
    "            else:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            if self.halt_on_error:\n",
    "                raise\n",
    "            else:\n",
    "                if self.is_verbose:\n",
    "                    str_e = str(e)\n",
    "                    self.logger.info(f'An exception occurred: {str_e}')\n",
    "                    self.logger.info(traceback.format_exc())\n",
    "                return None\n",
    "\n",
    "        return (response, message_id)\n",
    "        \n",
    "\n",
    "    def bad_response_output(self, error):\n",
    "        # general function for informing the user when an error occurs\n",
    "        if self.halt_on_error:\n",
    "            raise Exception(error)\n",
    "        else:\n",
    "            if self.is_verbose:\n",
    "                self.logger.info(f'Error - {error}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c0808b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:37.780204Z",
     "start_time": "2025-06-15T23:18:37.774613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama_4_maverick = ('meta-llama/llama-4-maverick', ['Fireworks', 'Together', 'Kluster'], 'llama_maverick')\n",
    "gemini_flash = ('google/gemini-2.5-flash-preview-05-20:thinking', ['Google', 'Google AI Studio'], 'gemini_flash')\n",
    "qwen_235B = ('qwen/qwen3-235b-a22b', ['DeepInfra', 'Kluster', 'Parasail', 'Together', 'Nebius'], 'qwen3_235B')  \n",
    "gpt_41 = ('openai/gpt-4.1', ['OpenAI'], 'gpt_41')\n",
    "gpt_41_mini = ('openai/gpt-4.1-mini', ['OpenAI'], 'gpt_41_mini')\n",
    "claude_sonnet = ('anthropic/claude-3.7-sonnet', ['Anthropic', 'Amazon Bedrock', 'Google', 'Google AI Studio'], 'claude_sonnet')\n",
    "grok_3 = ('x-ai/grok-3-beta', ['xAI'], 'grok3_beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ac189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5aa97a4",
   "metadata": {},
   "source": [
    "# Example: We expect a simple string response from GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TO_EVALUATE = gpt_41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97be0db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:38.857047Z",
     "start_time": "2025-06-15T23:18:38.852318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# specify GPT output json schema for a simple string response\n",
    "# all response schemas must contain \"refusal\" and \"reason_for_refusal\" fields\n",
    "simple_string_response_json = {\n",
    "    \"name\": \"simple_string_response_json\",\n",
    "    \"description\": \"Schema for a simple string response with refusal tracking\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"description\": \"JSON schema for a simple string response\",\n",
    "        \"properties\": {\n",
    "            \"response\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The generated output by GPT, formatted as a plain string\"\n",
    "            }\n",
    "        },\n",
    "        \"additionalProperties\": False,\n",
    "        \"required\": [\"response\"]\n",
    "    },\n",
    "    \"strict\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95702c24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:39.435989Z",
     "start_time": "2025-06-15T23:18:39.429698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def example_messaging_wrapper(chat, system_role, message, json_schema):\n",
    "    # with halt_on_error set to True in ChatGPT class, \n",
    "    # we use exception propogation to handle errors and edge-cases\n",
    "    response, message_history_id = None, -1\n",
    "    try:\n",
    "        response, message_history_id = chat.send_message(system_role=system_role,\n",
    "                                                         message=message, json_schema=json_schema,\n",
    "                                                         validate_response=True)\n",
    "        assert response is not None\n",
    "        response_json = json.loads(response.choices[0].message.content)\n",
    "        response_str = response_json[\"response\"]\n",
    "    except Exception as e:\n",
    "        response_json = {}\n",
    "        response_str = ''\n",
    "        chat.logger.info(f'Messaging wrapper failure - {str(e)}')\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    cost, n_prompt_tokens, n_completion_tokens = chat.get_running_cost_num_prompt_completion_tokens()\n",
    "    last_messages_sent_to_gpt = '' if (message_history_id not in chat.message_history) else chat.message_history[message_history_id]\n",
    "    print(f'Messages to GPT:\\n{last_messages_sent_to_gpt}')\n",
    "    print(f'Response from GPT:\\n{response_str}')\n",
    "    print(f'Cost: ${cost:.5f}')\n",
    "    \n",
    "    return response, message_history_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aeeb7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:44.423047Z",
     "start_time": "2025-06-15T23:18:40.029328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:processing message with 13 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages to GPT:\n",
      "[{'role': 'system', 'content': 'you are a helpful assistant.'}, {'role': 'user', 'content': 'help me bake a vanilla cake.'}]\n",
      "Response from GPT:\n",
      "Sure! Here’s a simple vanilla cake recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 and 1/2 cups (190g) all-purpose flour\n",
      "- 1 cup (200g) sugar\n",
      "- 1/2 cup (115g) unsalted butter, softened\n",
      "- 2 large eggs\n",
      "- 1/2 cup (120ml) milk\n",
      "- 2 tsp vanilla extract\n",
      "- 1 and 1/2 tsp baking powder\n",
      "- 1/4 tsp salt\n",
      "\n",
      "Instructions:\n",
      "1. Preheat your oven to 350°F (175°C). Grease and flour an 8-inch round cake pan.\n",
      "2. In a bowl, whisk together flour, baking powder, and salt.\n",
      "3. In another bowl, beat the butter and sugar until light and fluffy. Add eggs one at a time, beating well after each. Mix in vanilla extract.\n",
      "4. Add the dry ingredients to the wet mixture in three parts, alternating with the milk. Start and end with the dry ingredients. Mix until just combined.\n",
      "5. Pour the batter into the prepared pan and smooth the top.\n",
      "6. Bake for 25-30 minutes, or until a toothpick inserted in the center comes out clean.\n",
      "7. Let the cake cool in the pan for 10 minutes, then turn out onto a wire rack to cool completely.\n",
      "\n",
      "Enjoy your homemade vanilla cake!\n",
      "Cost: $0.00253\n"
     ]
    }
   ],
   "source": [
    "# specify system role and user message\n",
    "system_role = 'you are a helpful assistant.'\n",
    "message = f'help me bake a vanilla cake.'\n",
    "\n",
    "# create a single instance of ChatGPT \n",
    "# so that we can keep track of running costs\n",
    "chat = ChatGPT(model_provider_order=MODEL_TO_EVALUATE)\n",
    "\n",
    "response, message_history_id = example_messaging_wrapper(chat, system_role, message, simple_string_response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09d979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd8b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58b01098",
   "metadata": {},
   "source": [
    "# AAPECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aec27c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:46.171433Z",
     "start_time": "2025-06-15T23:18:45.160861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0c24367",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:46.200779Z",
     "start_time": "2025-06-15T23:18:46.174266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questions_list = [\n",
    "    {'text': 'Worry about things', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Make friends easily', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Have a vivid imagination', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Trust others', 'keyed': 'plus', 'domain': 'A'},\n",
    "    {'text': 'Complete tasks successfully', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Get angry easily', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Love large parties', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Believe in the importance of art', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Use others for my own ends', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Like to tidy up', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Often feel blue', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Take charge', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Experience my emotions intensely', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Love to help others', 'keyed': 'plus', 'domain': 'A'},\n",
    "    {'text': 'Keep my promises', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Find it difficult to approach others', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Am always busy', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Prefer variety to routine', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Love a good fight', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Work hard', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Go on binges', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Love excitement', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Love to read challenging material', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Believe that I am better than others', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Am always prepared', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Panic easily', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Radiate joy', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Tend to vote for liberal political candidates', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Sympathize with the homeless', 'keyed': 'plus', 'domain': 'A'},\n",
    "    {'text': 'Jump into things without thinking', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Fear for the worst', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Feel comfortable around people', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Enjoy wild flights of fantasy', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Believe that others have good intentions', 'keyed': 'plus', 'domain': 'A'},\n",
    "    {'text': 'Excel in what I do', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Get irritated easily', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Talk to a lot of different people at parties', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'See beauty in things that others might not notice', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Cheat to get ahead', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Often forget to put things back in their proper place', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Dislike myself', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Try to lead others', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Feel others\\' emotions', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Am concerned about others', 'keyed': 'plus', 'domain': 'A'},\n",
    "    {'text': 'Tell the truth', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Am afraid to draw attention to myself', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Am always on the go', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Prefer to stick with things that I know', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': 'Yell at people', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Do more than what\\'s expected of me', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Rarely overindulge', 'keyed': 'minus', 'domain': 'N'},\n",
    "    {'text': 'Seek adventure', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Avoid philosophical discussions', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': 'Think highly of myself', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Carry out my plans', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Become overwhelmed by events', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Have a lot of fun', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Believe that there is no absolute right and wrong', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Feel sympathy for those who are worse off than myself', 'keyed': 'plus', 'domain': 'A'},\n",
    "    {'text': 'Make rash decisions', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Am afraid of many things', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Avoid contacts with others', 'keyed': 'minus', 'domain': 'E'},\n",
    "    {'text': 'Love to daydream', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Trust what people say', 'keyed': 'plus', 'domain': 'A'},\n",
    "    {'text': 'Handle tasks smoothly', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Lose my temper', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Prefer to be alone', 'keyed': 'minus', 'domain': 'E'},\n",
    "    {'text': 'Do not like poetry', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': 'Take advantage of others', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Leave a mess in my room', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Am often down in the dumps', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Take control of things', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Rarely notice my emotional reactions', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': 'Am indifferent to the feelings of others', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Break rules', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Only feel comfortable with friends', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Do a lot in my spare time', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Dislike changes', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': 'Insult people', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Do just enough work to get by', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Easily resist temptations', 'keyed': 'minus', 'domain': 'N'},\n",
    "    {'text': 'Enjoy being reckless', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Have difficulty understanding abstract ideas', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': 'Have a high opinion of myself', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Waste my time', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': \"Feel that I'm unable to deal with things\", 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Love life', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Tend to vote for conservative political candidates', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': \"Am not interested in other people's problems\", 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Rush into things', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Get stressed out easily', 'keyed': 'plus', 'domain': 'N'},\n",
    "    {'text': 'Keep others at a distance', 'keyed': 'minus', 'domain': 'E'},\n",
    "    {'text': 'Like to get lost in thought', 'keyed': 'plus', 'domain': 'O'},\n",
    "    {'text': 'Distrust people', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Know how to get things done', 'keyed': 'plus', 'domain': 'C'},\n",
    "    {'text': 'Am not easily annoyed', 'keyed': 'minus', 'domain': 'N'},\n",
    "    {'text': 'Avoid crowds', 'keyed': 'minus', 'domain': 'E'},\n",
    "    {'text': 'Do not enjoy going to art museums', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': \"Obstruct others' plans\", 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Leave my belongings around', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Feel comfortable with myself', 'keyed': 'minus', 'domain': 'N'},\n",
    "    {'text': 'Wait for others to lead the way', 'keyed': 'minus', 'domain': 'E'},\n",
    "    {'text': \"Don't understand people who get emotional\", 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': 'Take no time for others', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Break my promises', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Am not bothered by difficult social situations', 'keyed': 'minus', 'domain': 'N'},\n",
    "    {'text': 'Like to take it easy', 'keyed': 'minus', 'domain': 'E'},\n",
    "    {'text': 'Am attached to conventional ways', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': 'Get back at others', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Put little time and effort into my work', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Am able to control my cravings', 'keyed': 'minus', 'domain': 'N'},\n",
    "    {'text': 'Act wild and crazy', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Am not interested in theoretical discussions', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': 'Boast about my virtues', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Have difficulty starting tasks', 'keyed': 'minus', 'domain': 'C'},\n",
    "    {'text': 'Remain calm under pressure', 'keyed': 'minus', 'domain': 'N'},\n",
    "    {'text': 'Look at the bright side of life', 'keyed': 'plus', 'domain': 'E'},\n",
    "    {'text': 'Believe that we should be tough on crime', 'keyed': 'minus', 'domain': 'O'},\n",
    "    {'text': 'Try not to think about the needy', 'keyed': 'minus', 'domain': 'A'},\n",
    "    {'text': 'Act without thinking', 'keyed': 'minus', 'domain': 'C'}\n",
    "]\n",
    "\n",
    "for i in range(len(questions_list)):\n",
    "    questions_list[i]['text'] = f'Question {i+1}: ' + questions_list[i]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = './data/AAPECS/'  # please contact the authors for access to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be3f13fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:53.956412Z",
     "start_time": "2025-06-15T23:18:47.179552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4868ab03994db2be2beca97fb1885b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
     ]
    }
   ],
   "source": [
    "pheno_df = pd.read_csv(f'{DATA_ROOT}/eod_new_time.csv')\n",
    "data_root = f'{DATA_ROOT}/raw_video_logs'\n",
    "data_files = [f for f in listdir(data_root) if isfile(join(data_root, f))]\n",
    "\n",
    "sub_transcripts = {}\n",
    "sub_lengths = {}\n",
    "\n",
    "for file in tqdm(data_files):\n",
    "    df = pd.read_csv(f'{data_root}/{file}')\n",
    "    df = df[(df.values[:, -1] != 'NO_ANSWER') & (df.values[:, -1] != 'SKIPPED')]\n",
    "\n",
    "    dates = [x.replace('/', '_') for x in df['Survey Submitted Date'].values]  # dd_mm_yyyy\n",
    "    times = [x.replace(':', '-') for x in df['Survey Submitted Time'].values]  # dd_mm_yyyy\n",
    "    addresses = df.values[:, -1]\n",
    "    userid = df['User Id'].values\n",
    "    usernum = file.lower().replace('eod', '').replace('vids', '').replace('videos', '').replace('.csv', '').replace('video', '')\n",
    "    usernum = int(usernum)\n",
    "    triggers = [x.replace(' ', '') for x in df['Trigger Type'].values]\n",
    "\n",
    "    assert np.all(['http' in x for x in addresses])\n",
    "    assert np.all((df['Trigger Type'].values == \"DAILY\") | (df['Trigger Type'].values == \"DELETED TRIGGER\") | (df['Trigger Type'].values == \"ONCE\"))\n",
    "    assert np.all([x.split('/')[-1].split('.')][-1] == 'mp4' for x in addresses)\n",
    "    \n",
    "    sub_pheno_df = pheno_df[pheno_df.participantID == usernum]\n",
    "    if sub_pheno_df.shape[0] == 0: continue\n",
    "\n",
    "    \n",
    "    for i in range(len(addresses)):\n",
    "        txt = json.load(open(f'{DATA_ROOT}/transcripts_json/{usernum}/{usernum}_{dates[i]}_{times[i]}_{triggers[i]}_{userid[i]}.json'))['text'].strip()\n",
    "        \n",
    "        day, month, year = dates[i].split('_')\n",
    "        sub = usernum\n",
    "        if sub not in sub_transcripts:\n",
    "            sub_transcripts[sub] = []\n",
    "        sub_transcripts[sub].append(txt)\n",
    "        \n",
    "        recording_length = json.load(open(f'{DATA_ROOT}/transcripts_json/{usernum}/{usernum}_{dates[i]}_{times[i]}_{triggers[i]}_{userid[i]}.json'))['segments'][-1]['end']\n",
    "        if sub not in sub_lengths:\n",
    "            sub_lengths[sub] = []\n",
    "        sub_lengths[sub].append(recording_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ab56af0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:56.007974Z",
     "start_time": "2025-06-15T23:18:56.002851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_NEO_FFI_prompt(thoughts, questions):\n",
    "    prompt_template = f\"\"\"\n",
    "Your task is to respond to the following IPIP-NEO-120 questions based on the participant's daily diaries of the most significant event that occurred during the day, provided below. Respond as though you are the individual who generated these thoughts, reflecting their personality traits.\n",
    "Base your answer on inferred personality traits. Think carefully about what the thoughts imply about tendencies and behaviors.\n",
    "\n",
    "IPIP-NEO-120 questions to answer:\n",
    "{questions}\n",
    "\n",
    "For each question, select the most appropriate option:\n",
    "- Very Inaccurate: The statement is definitely false or the participant would strongly disagree with it.\n",
    "- Moderately Inaccurate: The statement is mostly false or the participant would generally disagree with it.\n",
    "- Neither Accurate nor Inaccurate: The participant would be neutral on the statement, cannot decide, or find the statement equally true and false.\n",
    "- Moderately Accurate: The statement is mostly true or the participant would generally agree with it.\n",
    "- Very Accurate: The statement is definitely true or the participant would strongly agree with it.\n",
    "\n",
    "Then:\n",
    "Provide 3-5 high-level themes that explain *why* you gave the ratings above. Do not provide one theme per question, instead focus on the most significant patterns or insights that emerge across the questions above. \n",
    "For each theme, include:\n",
    "  - A brief explanation of a theme that informed your judgment.\n",
    "  - All direct quotes from the participant's diaries that support the theme and explanation.\n",
    "  - Remember: Do not paraphrase or invent quotes, the quotes must be exactly as given in the participant's diaries below.\n",
    "\n",
    "Participant's daily diaries:\n",
    "{thoughts}\n",
    "\"\"\"\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce840783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:18:56.013309Z",
     "start_time": "2025-06-15T23:18:56.009589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name_mapping_aapecs = {\n",
    "    'neoOpenness': 'O',\n",
    "    'neoConscientiousness': 'C',\n",
    "    'neoExtraversion': 'E',\n",
    "    'neoAgreeableness': 'A',\n",
    "    'neoNeuroticism': 'N'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "682fba95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:19:00.041447Z",
     "start_time": "2025-06-15T23:19:00.033520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_required_fields(schema, parent_key=''):\n",
    "    required_fields = []\n",
    "    if 'required' in schema:\n",
    "        # If parent_key exists, prefix it to the required field names\n",
    "        for field in schema['required']:\n",
    "            full_field_name = f\"{parent_key}.{field}\" if parent_key else field\n",
    "            required_fields.append(full_field_name)\n",
    "\n",
    "    if 'properties' in schema:\n",
    "        for key, value in schema['properties'].items():\n",
    "            new_parent_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "            required_fields.extend(find_required_fields(value, new_parent_key))\n",
    "\n",
    "    return required_fields\n",
    "\n",
    "\n",
    "def get_value_from_path(data, path):\n",
    "    keys = path.split('.')\n",
    "    for key in keys:\n",
    "        if isinstance(data, list):\n",
    "            key = int(key)\n",
    "        data = data[key]\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_required_values(schema, response):\n",
    "    required_fields = find_required_fields(schema)\n",
    "    required_values = {}\n",
    "\n",
    "    for field in required_fields:\n",
    "        try:\n",
    "            value = get_value_from_path(response, field)\n",
    "            required_values[field] = value\n",
    "        except KeyError:\n",
    "            required_values[field] = None  # Handle missing values if needed\n",
    "\n",
    "    return required_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b7db536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:19:01.231162Z",
     "start_time": "2025-06-15T23:19:01.225514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generic_messaging_wrapper(chat, system_role, message, json_schema):\n",
    "    # with halt_on_error set to True in ChatGPT class, \n",
    "    # we use exception propogation to handle errors and edge-cases\n",
    "    message_history_id = -1\n",
    "    required_values = None\n",
    "    try:\n",
    "        response, message_history_id = chat.send_message(system_role=system_role,\n",
    "                                                         message=message, json_schema=json_schema)\n",
    "        assert response is not None\n",
    "        response_json = json.loads(response.choices[0].message.content)\n",
    "        required_values = response_json\n",
    "    except Exception as e:\n",
    "        response_json = {}\n",
    "        chat.logger.info(f'Messaging wrapper failure - {str(e)}')\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    cost, n_prompt_tokens, n_completion_tokens = chat.get_running_cost_num_prompt_completion_tokens()\n",
    "    return required_values, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3972fa8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:19:01.813679Z",
     "start_time": "2025-06-15T23:19:01.808043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "system_role = ''\n",
    "print(system_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "927e1b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:19:03.016191Z",
     "start_time": "2025-06-15T23:19:03.003231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import difflib\n",
    "import unicodedata\n",
    "\n",
    "def normalize_text(s, case_insensitive=True, unicode_normalize=True):\n",
    "    \"\"\"\n",
    "    - Strip leading/trailing whitespace\n",
    "    - Collapse all internal whitespace to single spaces\n",
    "    - Optionally lowercase\n",
    "    - Optionally apply Unicode NFC normalization\n",
    "    \"\"\"\n",
    "    # Unicode normalization (e.g. é → e + ´)\n",
    "    if unicode_normalize:\n",
    "        s = unicodedata.normalize('NFC', s)\n",
    "    # Collapse whitespace\n",
    "    s = ' '.join(s.split())\n",
    "    # Lowercase if desired\n",
    "    if case_insensitive:\n",
    "        s = s.lower()\n",
    "    s = s.replace('\\n', ' ')\n",
    "    return s\n",
    "\n",
    "def longest_common_substring(a_raw, b_raw):\n",
    "    \"\"\"\n",
    "    Returns the longest substring common to both a and b.\n",
    "    Uses difflib.SequenceMatcher under the hood.\n",
    "    \"\"\"\n",
    "    a = normalize_text(a_raw)\n",
    "    b = normalize_text(b_raw)\n",
    "\n",
    "    matcher = difflib.SequenceMatcher(None, a, b)\n",
    "    match = matcher.find_longest_match(0, len(a), 0, len(b))\n",
    "    if match.size == 0: return ''\n",
    "    return a[match.a : match.a + match.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c89d52aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:19:03.853238Z",
     "start_time": "2025-06-15T23:19:03.844863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def generate_neo_schema(questions):\n",
    "    \"\"\"\n",
    "    Given a list of strings like \"Question 1: I am not a worrier.\",\n",
    "    returns a JSON‐schema dict where each question becomes an enum‐string field\n",
    "    (Strongly Disagree … Strongly Agree), plus a 'justifications' array.\n",
    "    \"\"\"\n",
    "    OPTIONS = [\n",
    "        \"Very Inaccurate\",\n",
    "        \"Moderately Inaccurate\",\n",
    "        \"Neither Accurate nor Inaccurate\",\n",
    "        \"Moderately Accurate\",\n",
    "        \"Very Accurate\"\n",
    "    ]\n",
    "\n",
    "    properties = {}\n",
    "    required = []\n",
    "\n",
    "    for q in questions:\n",
    "        # e.g. \"Question 1\" → \"Question_1\"\n",
    "        key = q.split(':')[0].replace(' ', '_')\n",
    "        properties[key] = {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": f\"Response to '{q.strip()}'\",\n",
    "            \"enum\": OPTIONS\n",
    "        }\n",
    "        required.append(key)\n",
    "\n",
    "    # justifications stays the same\n",
    "    properties[\"justifications\"] = {\n",
    "        \"type\": \"array\",\n",
    "        \"description\": \"Each entry provides an explanation and supporting quotes.\",\n",
    "        \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"additionalProperties\": False,\n",
    "            \"properties\": {\n",
    "                \"explanation\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A brief explanation of a theme or observation.\"\n",
    "                },\n",
    "                \"quotes\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"Direct quotes from the stream of thoughts that support the explanation.\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"additionalProperties\": False,\n",
    "                        \"properties\": {\n",
    "                            \"text\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The exact quote.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"text\"]\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"explanation\", \"quotes\"]\n",
    "        }\n",
    "    }\n",
    "    required.append(\"justifications\")\n",
    "\n",
    "    schema = {\n",
    "        \"name\": \"neo_ffi_assessment_from_stream_of_thoughts\",\n",
    "        \"description\": (\n",
    "            \"Rates each NEO-FFI item from participant’s spontaneous stream of thoughts, \"\n",
    "            \"plus structured justifications with supporting quotes.\"\n",
    "        ),\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"additionalProperties\": False,\n",
    "            \"strict\": True,\n",
    "            \"properties\": properties,\n",
    "            \"required\": required\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc4b51bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:52:35.061291Z",
     "start_time": "2025-06-15T23:52:35.052927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def format_neo_summary(data, thoughts):\n",
    "    \"\"\"\n",
    "    Given a dict matching your NEO‐FFI schema—\n",
    "    with keys like \"Question_1\", \"Question_6\", … and a \"justifications\" list—\n",
    "    returns a nicely formatted multi‐line string.\n",
    "    \"\"\"\n",
    "    # 1) Collect and sort the question keys by their numeric index\n",
    "    q_keys = [k for k in data.keys() if re.match(r\"Question_\\d+$\", k)]\n",
    "    q_keys.sort(key=lambda k: int(k.split(\"_\")[1]))\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    \"\"\"\n",
    "    # 2) Add each question + response\n",
    "    for key in q_keys:\n",
    "        # turn \"Question_1\" → \"Question 1\"\n",
    "        pretty = key.replace(\"_\", \" \")\n",
    "        resp = data[key]\n",
    "        lines.append(f\"{pretty}: {resp}\")\n",
    "    \"\"\"\n",
    "\n",
    "    # 3) Add a spacer before justifications\n",
    "    lines.append(\"Justifications:\\n\")\n",
    "    \n",
    "    # 4) Enumerate through each justification entry\n",
    "    for i, entry in enumerate(data.get(\"justifications\", []), start=1):\n",
    "        lines.append(f\"Reason {i}\")\n",
    "        lines.append(entry[\"explanation\"])\n",
    "        \n",
    "        # Citation header\n",
    "        n_quotes = len(entry[\"quotes\"])\n",
    "        if   n_quotes == 1: lines.append(\"  Citation:\")\n",
    "        elif n_quotes > 1:  lines.append(\"  Citations:\")\n",
    "        \n",
    "        # The quotes themselves\n",
    "        for quote in entry[\"quotes\"]:\n",
    "            matched_quote = longest_common_substring(thoughts, quote['text'])\n",
    "            if len(matched_quote) > 0:\n",
    "                if len(matched_quote.split(' ')) > 4:\n",
    "                    lines.append(f\"    \\\"{matched_quote.strip()}\\\"\")\n",
    "        \n",
    "        # blank line between reasons\n",
    "        lines.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c9ddc4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:52:36.273820Z",
     "start_time": "2025-06-15T23:52:36.267151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_mapping = {\n",
    "    'Very Inaccurate': 0,\n",
    "    'Moderately Inaccurate': 1,\n",
    "    'Neither Accurate nor Inaccurate': 2,\n",
    "    'Moderately Accurate': 3,\n",
    "    'Very Accurate': 4,\n",
    "    None: np.nan\n",
    "}\n",
    "\n",
    "reverse_mapping = {\n",
    "    'Very Inaccurate': 4,\n",
    "    'Moderately Inaccurate': 3,\n",
    "    'Neither Accurate nor Inaccurate': 2,\n",
    "    'Moderately Accurate': 1,\n",
    "    'Very Accurate': 0,\n",
    "    None: np.nan\n",
    "}\n",
    "\n",
    "def score_neo_trait(json_response):\n",
    "    qs = [x for x in json_response if 'question' in x.lower()]\n",
    "    qs_scores = [json_response[x] for x in qs]\n",
    "    q_i = [int(x.split('_')[1])-1 for x in qs]\n",
    "    q_scale = [1 if questions_list[x]['keyed'] == 'plus' else -1 for x in q_i]\n",
    "    score = np.mean([response_mapping[score] if scale == 1 else reverse_mapping[score] for (score, scale) in zip(qs_scores, q_scale)])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef47f6ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:52:59.659430Z",
     "start_time": "2025-06-15T23:52:46.058180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:processing message with 3311 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.375\n",
      "Justifications:\n",
      "\n",
      "Reason 1\n",
      "Frequent worry, stress, and concern about safety and future events, especially related to driving and loved ones, indicate high neuroticism (worry, stress, fear for the worst).\n",
      "  Citations:\n",
      "    \"it seems to be happening a little bit more lately, and i don't know if it's because i'm driving more.\"\n",
      "    \"it's very concerning how often it happens, because i do drive for a living. i have to be mindful of other people, and it's scary, because i can't have an accident with my car.\"\n",
      "    \"i've again had so many different times where this has happened, starting to become worrisome.\"\n",
      "    \"that's been something that's been stressing me out every day.\"\n",
      "    \"she kind of fidgeted all night, so i was really stressed worrying about her.\"\n",
      "    \"it was a very stressful night, and then this morning, they wake me up very early, 5.30 in the morning usually, to feed them.\"\n",
      "\n",
      "Reason 2\n",
      "Despite stress, the participant is generally able to function, complete tasks, and maintain social relationships, suggesting resilience and some comfort in social situations.\n",
      "  Citations:\n",
      "    \". i've just been updating and trying to cross things off as i go along. so that's pretty much where i was today with things along with working. but i'm happy that i'm getting things done on my list.\"\n",
      "    \"so, today was a good day. it didn't have any problems, for the most part. i also got some laundry done, and some other chores around the house done. so, it was a relatively good day.\"\n",
      "    \". so, i basically was filling my freezer with food from the food that i had eaten already.\"\n",
      "    \"i cut my grass, organized my garage. i'm trying to get a lot of things done on my list as often as i can.\"\n",
      "\n",
      "Reason 3\n",
      "Participant experiences irritation and anger in response to external stressors (e.g., traffic), but does not report losing temper or acting out, indicating moderate irritability but not impulsive anger.\n",
      "  Citations:\n",
      "    \"had some issues at the airport, which made me a little bit angry, getting stuck in some traffic for an hour and a half. but again, i made it through the day.\"\n",
      "    \"i thought he was going to hit my car into the wall, just because he just seemed so erratic.\"\n",
      "\n",
      "Reason 4\n",
      "Participant does not report overindulgence, loss of control, or difficulty resisting temptations, and is able to manage daily routines and responsibilities.\n",
      "  Citations:\n",
      "    \"i made grape leaves, made my dog food. i make food from scratch for her. and cut up a lot of different things that i bought to put in my freezer, like a lamb. and salmon, etc.\"\n",
      "    \"i got a lot of things done on my list again today. i cut my grass, organized my garage.\"\n",
      "\n",
      "Reason 5\n",
      "Participant is able to engage in social activities, host friends, go on dates, and does not express discomfort in social situations, suggesting low social anxiety and comfort with others.\n",
      "  Citations:\n",
      "    \"my friend came over to my house, and we made tacos and watched a scary movie. so it was actually a very relaxing day. i felt very happy.\"\n",
      "    \"i went on a date, first date, with someone new. very nice man, we had a good time, had a few drinks, and talked for a little while.\"\n",
      "    \"hung out with my friend to have dinner, and watched the steelers game, unfortunately we lost, but we still had fun doing that.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = ChatGPT(model_provider_order=MODEL_TO_EVALUATE)\n",
    "\n",
    "subject = 54\n",
    "trait = 'neoNeuroticism'\n",
    "\n",
    "thoughts = '\\n'.join(sub_transcripts[subject])\n",
    "neu_questions = [x['text'] for x in questions_list if x['domain']==name_mapping_aapecs[trait]]\n",
    "neu_schema = generate_neo_schema(neu_questions)\n",
    "message = get_NEO_FFI_prompt(thoughts, \n",
    "                             '\\n'.join(neu_questions))\n",
    "required_values, cost = generic_messaging_wrapper(chat, system_role, message, neu_schema)\n",
    "\n",
    "trait_score = score_neo_trait(required_values)\n",
    "trait_reasoning = format_neo_summary(required_values, thoughts)\n",
    "\n",
    "print(trait_score)\n",
    "print(trait_reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfa3e936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:53:08.306219Z",
     "start_time": "2025-06-15T23:53:08.286504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>participantID</th>\n",
       "      <th>neoOpenness</th>\n",
       "      <th>neoConscientiousness</th>\n",
       "      <th>neoExtraversion</th>\n",
       "      <th>neoAgreeableness</th>\n",
       "      <th>neoNeuroticism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>1.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.458333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>3.041667</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>3.291667</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  participantID  neoOpenness  neoConscientiousness  \\\n",
       "0           0             85     1.875000              2.500000   \n",
       "1           1             54     2.083333              3.625000   \n",
       "2           2             78     2.333333              2.750000   \n",
       "3           3             97     2.375000              3.041667   \n",
       "4           4             48     1.708333              3.416667   \n",
       "\n",
       "   neoExtraversion  neoAgreeableness  neoNeuroticism  \n",
       "0         1.083333          2.916667        2.750000  \n",
       "1         2.125000          3.166667        1.833333  \n",
       "2         1.458333          3.333333        3.166667  \n",
       "3         1.750000          3.333333        1.833333  \n",
       "4         2.083333          3.291667        0.791667  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_scores = pd.read_csv(f'{DATA_ROOT}/aapecs_gpt_41_text_per_question_scores.csv')\n",
    "gpt_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7520d6ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:58:35.241676Z",
     "start_time": "2025-06-15T23:53:08.802823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bd2b92fdfe429a9e6048deff5786c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:processing message with 1456 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 3435 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1029 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 5323 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 3131 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 2923 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:processing message with 2652 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1859 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 2127 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1013 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1802 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 4212 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:processing message with 2368 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1828 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 3154 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1059 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 3545 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1208 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:processing message with 647 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 2379 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1853 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 3590 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1821 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 3767 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:processing message with 688 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 3531 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1070 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 2209 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 1018 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:processing message with 2132 tokens...\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for trait in tqdm(name_mapping_aapecs):\n",
    "    trait_scores_df = gpt_scores.sort_values(by=trait, ascending=True)[['participantID', trait]]\n",
    "    for i in tqdm(range(3), desc=trait, leave=False):\n",
    "        subject, true_trait_score = trait_scores_df.values[i, :]\n",
    "        chat = ChatGPT(model_provider_order=MODEL_TO_EVALUATE)\n",
    "        thoughts = '\\n'.join(sub_transcripts[subject])\n",
    "        neu_questions = [x['text'] for x in questions_list if x['domain']==name_mapping_aapecs[trait]]\n",
    "        neu_schema = generate_neo_schema(neu_questions)\n",
    "        message = get_NEO_FFI_prompt(thoughts, '\\n'.join(neu_questions))\n",
    "        required_values, cost = generic_messaging_wrapper(chat, system_role, message, neu_schema)\n",
    "        gpt_trait_score = score_neo_trait(required_values)\n",
    "        trait_reasoning = format_neo_summary(required_values, thoughts)  \n",
    "        outputs.append((subject, f'low_{trait}', true_trait_score, gpt_trait_score, trait_reasoning))\n",
    "        \n",
    "        subject, true_trait_score = trait_scores_df.values[-(i+1), :]\n",
    "        chat = ChatGPT(model_provider_order=MODEL_TO_EVALUATE)\n",
    "        thoughts = '\\n'.join(sub_transcripts[subject])\n",
    "        neu_questions = [x['text'] for x in questions_list if x['domain']==name_mapping_aapecs[trait]]\n",
    "        neu_schema = generate_neo_schema(neu_questions)\n",
    "        message = get_NEO_FFI_prompt(thoughts, '\\n'.join(neu_questions))\n",
    "        required_values, cost = generic_messaging_wrapper(chat, system_role, message, neu_schema)\n",
    "        gpt_trait_score = score_neo_trait(required_values)\n",
    "        trait_reasoning = format_neo_summary(required_values, thoughts)  \n",
    "        outputs.append((subject, f'high_{trait}', true_trait_score, gpt_trait_score, trait_reasoning))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd4babae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:58:35.325687Z",
     "start_time": "2025-06-15T23:58:35.243561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scales_df = pd.read_csv(f'{DATA_ROOT}/selfReport.csv')\n",
    "scales_df = scales_df[scales_df.participantID.isin([int(x) for x in sub_lengths])]\n",
    "scales_df = scales_df[['participantID']+list(cols_of_interest)]\n",
    "print(scales_df.shape)\n",
    "scales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59582440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:58:35.367039Z",
     "start_time": "2025-06-15T23:58:35.327044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(outputs)\n",
    "df.columns = ['participantID', 'trait_description', 'self_reported', 'gpt_predicted', 'gpt_reasoning']\n",
    "df[['level','trait']] = df['trait_description'].str.split('_', n=1, expand=True)\n",
    "df = df.sort_values(by=['trait', 'level'])\n",
    "\n",
    "true_scales = []\n",
    "for sub_i, sub in enumerate(df.participantID.values):\n",
    "    s_trait = df.trait.values[sub_i]\n",
    "    t_v = scales_df[scales_df.participantID == sub][s_trait].values.flatten()[0]\n",
    "    true_scales.append(t_v)\n",
    "df['self_reported'] = true_scales\n",
    "\n",
    "df = df[['level', 'trait', 'gpt_reasoning']] #'subject', 'self_reported', 'gpt_predicted']]\n",
    "\n",
    "df.to_csv(f'{DATA_ROOT}/aapecs_gpt_41_reasoning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e6950da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T00:00:28.138575Z",
     "start_time": "2025-06-16T00:00:28.099910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .jupyter-widgets {color: #d5d5d5 !important;}\n",
       "            .widget-label {color: #d5d5d5 !important;}\n",
       "        </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>trait_description</th>\n",
       "      <th>self_reported</th>\n",
       "      <th>gpt_predicted</th>\n",
       "      <th>gpt_reasoning</th>\n",
       "      <th>level</th>\n",
       "      <th>trait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>125.0</td>\n",
       "      <td>high_neoAgreeableness</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nStrong concern an...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoAgreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17.0</td>\n",
       "      <td>high_neoAgreeableness</td>\n",
       "      <td>3.291667</td>\n",
       "      <td>3.541667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nStrong concern fo...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoAgreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50.0</td>\n",
       "      <td>high_neoAgreeableness</td>\n",
       "      <td>3.708333</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nStrong concern fo...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoAgreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>67.0</td>\n",
       "      <td>low_neoAgreeableness</td>\n",
       "      <td>2.208333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nThe diaries provi...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoAgreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.0</td>\n",
       "      <td>low_neoAgreeableness</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>2.458333</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nStrong emotional ...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoAgreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>51.0</td>\n",
       "      <td>low_neoAgreeableness</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nImpulsivity and d...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoAgreeableness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>111.0</td>\n",
       "      <td>high_neoConscientiousness</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nConsistent eviden...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoConscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>87.0</td>\n",
       "      <td>high_neoConscientiousness</td>\n",
       "      <td>3.291667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nStrong sense of r...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoConscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35.0</td>\n",
       "      <td>high_neoConscientiousness</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nStrong sense of r...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoConscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>105.0</td>\n",
       "      <td>low_neoConscientiousness</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nChronic procrasti...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoConscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>103.0</td>\n",
       "      <td>low_neoConscientiousness</td>\n",
       "      <td>2.208333</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nEmotional distres...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoConscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51.0</td>\n",
       "      <td>low_neoConscientiousness</td>\n",
       "      <td>2.791667</td>\n",
       "      <td>1.791667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nImpulsivity and e...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoConscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.0</td>\n",
       "      <td>high_neoExtraversion</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nFrequent social e...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoExtraversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30.0</td>\n",
       "      <td>high_neoExtraversion</td>\n",
       "      <td>3.208333</td>\n",
       "      <td>3.541667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nStrong enjoyment ...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoExtraversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.0</td>\n",
       "      <td>high_neoExtraversion</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>2.958333</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nThe participant i...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoExtraversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>83.0</td>\n",
       "      <td>low_neoExtraversion</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nConsistent discom...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoExtraversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58.0</td>\n",
       "      <td>low_neoExtraversion</td>\n",
       "      <td>1.236111</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nLow social engage...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoExtraversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>52.0</td>\n",
       "      <td>low_neoExtraversion</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nStrong discomfort...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoExtraversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>81.0</td>\n",
       "      <td>high_neoNeuroticism</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nHigh levels of an...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoNeuroticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.0</td>\n",
       "      <td>high_neoNeuroticism</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nHigh emotional re...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoNeuroticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>103.0</td>\n",
       "      <td>high_neoNeuroticism</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nHigh emotional re...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoNeuroticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>28.0</td>\n",
       "      <td>low_neoNeuroticism</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nPositive mood and...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoNeuroticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30.0</td>\n",
       "      <td>low_neoNeuroticism</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nThe participant i...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoNeuroticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>87.0</td>\n",
       "      <td>low_neoNeuroticism</td>\n",
       "      <td>1.486111</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nConsistently posi...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoNeuroticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>high_neoOpenness</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nThe participant e...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoOpenness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.0</td>\n",
       "      <td>high_neoOpenness</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nThe participant e...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoOpenness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86.0</td>\n",
       "      <td>high_neoOpenness</td>\n",
       "      <td>3.291667</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nStrong emotional ...</td>\n",
       "      <td>high</td>\n",
       "      <td>neoOpenness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.0</td>\n",
       "      <td>low_neoOpenness</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nThe participant's...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoOpenness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.0</td>\n",
       "      <td>low_neoOpenness</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nFocus on family, ...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoOpenness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.0</td>\n",
       "      <td>low_neoOpenness</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>Justifications:\\n\\nReason 1\\nThe participant's...</td>\n",
       "      <td>low</td>\n",
       "      <td>neoOpenness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    participantID          trait_description  self_reported  gpt_predicted  \\\n",
       "19          125.0      high_neoAgreeableness       3.083333       3.625000   \n",
       "21           17.0      high_neoAgreeableness       3.291667       3.541667   \n",
       "23           50.0      high_neoAgreeableness       3.708333       3.625000   \n",
       "18           67.0       low_neoAgreeableness       2.208333       2.000000   \n",
       "20           10.0       low_neoAgreeableness       3.375000       2.458333   \n",
       "22           51.0       low_neoAgreeableness       2.250000       2.000000   \n",
       "7           111.0  high_neoConscientiousness       2.750000       3.666667   \n",
       "9            87.0  high_neoConscientiousness       3.291667       3.833333   \n",
       "11           35.0  high_neoConscientiousness       3.666667       3.833333   \n",
       "6           105.0   low_neoConscientiousness       0.750000       1.500000   \n",
       "8           103.0   low_neoConscientiousness       2.208333       1.916667   \n",
       "10           51.0   low_neoConscientiousness       2.791667       1.791667   \n",
       "13           10.0       high_neoExtraversion       3.250000       2.750000   \n",
       "15           30.0       high_neoExtraversion       3.208333       3.541667   \n",
       "17           32.0       high_neoExtraversion       2.625000       2.958333   \n",
       "12           83.0        low_neoExtraversion       0.416667       0.791667   \n",
       "14           58.0        low_neoExtraversion       1.236111       0.916667   \n",
       "16           52.0        low_neoExtraversion       0.791667       1.041667   \n",
       "25           81.0        high_neoNeuroticism       3.333333       3.583333   \n",
       "27            6.0        high_neoNeuroticism       1.583333       2.916667   \n",
       "29          103.0        high_neoNeuroticism       2.833333       3.083333   \n",
       "24           28.0         low_neoNeuroticism       0.708333       0.000000   \n",
       "26           30.0         low_neoNeuroticism       0.750000       0.416667   \n",
       "28           87.0         low_neoNeuroticism       1.486111       0.291667   \n",
       "1            70.0           high_neoOpenness       3.333333       3.666667   \n",
       "3            56.0           high_neoOpenness       3.083333       3.333333   \n",
       "5            86.0           high_neoOpenness       3.291667       3.083333   \n",
       "0           112.0            low_neoOpenness       1.125000       1.750000   \n",
       "2            59.0            low_neoOpenness       1.875000       1.708333   \n",
       "4            37.0            low_neoOpenness       1.916667       1.833333   \n",
       "\n",
       "                                        gpt_reasoning level  \\\n",
       "19  Justifications:\\n\\nReason 1\\nStrong concern an...  high   \n",
       "21  Justifications:\\n\\nReason 1\\nStrong concern fo...  high   \n",
       "23  Justifications:\\n\\nReason 1\\nStrong concern fo...  high   \n",
       "18  Justifications:\\n\\nReason 1\\nThe diaries provi...   low   \n",
       "20  Justifications:\\n\\nReason 1\\nStrong emotional ...   low   \n",
       "22  Justifications:\\n\\nReason 1\\nImpulsivity and d...   low   \n",
       "7   Justifications:\\n\\nReason 1\\nConsistent eviden...  high   \n",
       "9   Justifications:\\n\\nReason 1\\nStrong sense of r...  high   \n",
       "11  Justifications:\\n\\nReason 1\\nStrong sense of r...  high   \n",
       "6   Justifications:\\n\\nReason 1\\nChronic procrasti...   low   \n",
       "8   Justifications:\\n\\nReason 1\\nEmotional distres...   low   \n",
       "10  Justifications:\\n\\nReason 1\\nImpulsivity and e...   low   \n",
       "13  Justifications:\\n\\nReason 1\\nFrequent social e...  high   \n",
       "15  Justifications:\\n\\nReason 1\\nStrong enjoyment ...  high   \n",
       "17  Justifications:\\n\\nReason 1\\nThe participant i...  high   \n",
       "12  Justifications:\\n\\nReason 1\\nConsistent discom...   low   \n",
       "14  Justifications:\\n\\nReason 1\\nLow social engage...   low   \n",
       "16  Justifications:\\n\\nReason 1\\nStrong discomfort...   low   \n",
       "25  Justifications:\\n\\nReason 1\\nHigh levels of an...  high   \n",
       "27  Justifications:\\n\\nReason 1\\nHigh emotional re...  high   \n",
       "29  Justifications:\\n\\nReason 1\\nHigh emotional re...  high   \n",
       "24  Justifications:\\n\\nReason 1\\nPositive mood and...   low   \n",
       "26  Justifications:\\n\\nReason 1\\nThe participant i...   low   \n",
       "28  Justifications:\\n\\nReason 1\\nConsistently posi...   low   \n",
       "1   Justifications:\\n\\nReason 1\\nThe participant e...  high   \n",
       "3   Justifications:\\n\\nReason 1\\nThe participant e...  high   \n",
       "5   Justifications:\\n\\nReason 1\\nStrong emotional ...  high   \n",
       "0   Justifications:\\n\\nReason 1\\nThe participant's...   low   \n",
       "2   Justifications:\\n\\nReason 1\\nFocus on family, ...   low   \n",
       "4   Justifications:\\n\\nReason 1\\nThe participant's...   low   \n",
       "\n",
       "                   trait  \n",
       "19      neoAgreeableness  \n",
       "21      neoAgreeableness  \n",
       "23      neoAgreeableness  \n",
       "18      neoAgreeableness  \n",
       "20      neoAgreeableness  \n",
       "22      neoAgreeableness  \n",
       "7   neoConscientiousness  \n",
       "9   neoConscientiousness  \n",
       "11  neoConscientiousness  \n",
       "6   neoConscientiousness  \n",
       "8   neoConscientiousness  \n",
       "10  neoConscientiousness  \n",
       "13       neoExtraversion  \n",
       "15       neoExtraversion  \n",
       "17       neoExtraversion  \n",
       "12       neoExtraversion  \n",
       "14       neoExtraversion  \n",
       "16       neoExtraversion  \n",
       "25        neoNeuroticism  \n",
       "27        neoNeuroticism  \n",
       "29        neoNeuroticism  \n",
       "24        neoNeuroticism  \n",
       "26        neoNeuroticism  \n",
       "28        neoNeuroticism  \n",
       "1            neoOpenness  \n",
       "3            neoOpenness  \n",
       "5            neoOpenness  \n",
       "0            neoOpenness  \n",
       "2            neoOpenness  \n",
       "4            neoOpenness  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(outputs)\n",
    "df.columns = ['participantID', 'trait_description', 'self_reported', 'gpt_predicted', 'gpt_reasoning']\n",
    "df[['level','trait']] = df['trait_description'].str.split('_', n=1, expand=True)\n",
    "df = df.sort_values(by=['trait', 'level'])\n",
    "\n",
    "true_scales = []\n",
    "for sub_i, sub in enumerate(df.participantID.values):\n",
    "    s_trait = df.trait.values[sub_i]\n",
    "    t_v = scales_df[scales_df.participantID == sub][s_trait].values.flatten()[0]\n",
    "    true_scales.append(t_v)\n",
    "df['self_reported'] = true_scales\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1985ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db8e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a462b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_testing",
   "language": "python",
   "name": "llm_testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
